apiVersion: v1
kind: ConfigMap
metadata: { name: spark-demo, namespace: spark }
data:
  demo.py: |
    from pyspark.sql import SparkSession
    spark = SparkSession.builder.getOrCreate()
    df = spark.createDataFrame([(1,"a"),(2,"b"),(3,"c")], ["id","val"])
    df.printSchema(); df.show(truncate=False)
---
apiVersion: batch/v1
kind: Job
metadata: { generateName: spark-demo-, namespace: spark }
spec:
  backoffLimit: 0
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: submit
          image: apache/spark:3.5.1
          volumeMounts: [{ name: code, mountPath: /opt/app }]
          command: ["/opt/spark/bin/spark-submit"]
          args:
            - --master
            - spark://spark-master-svc:7077
            - --deploy-mode
            - cluster
            - --conf
            - spark.dynamicAllocation.enabled=false
            - --conf
            - spark.driver.bindAddress=0.0.0.0
            - /opt/app/demo.py
      volumes: [{ name: code, configMap: { name: spark-demo } }]
